% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hyperopt.R
\name{hyperopt}
\alias{hyperopt}
\title{Tune Hyperparameters for a machine learning task}
\usage{
hyperopt(task, learner = NULL, par.config = NULL, hyper.control = NULL,
  show.info = getMlrOptions()$show.info)
}
\arguments{
\item{task}{[\code{Task}]
The Task}

\item{learner}{[\code{Learner}]
The learner that is subject to the Hyperparameter Tuning.
If no learner is given the learner referenced in the \code{par.config} will be used, if available.}

\item{par.config}{[\code{\link{ParConfig}}]
The Parameter Configuration}

\item{hyper.control}{[\code{\link{HyperControl}}]
The Hyperparameter Control Object}

\item{show.info}{[\code{logical(1)}]\cr
Print verbose output on console?
Default is set via \code{\link{configureMlr}}.}
}
\value{
[\code{\link[mlr]{TuneResult}}]
}
\description{
Tunes the Hyperparameters for a given task and learner.
Tries to find the best parameter set to tune for the given learner.
}
\examples{
# the shortest way of hyperparameter optimization
hyperopt(iris.task, "classif.svm")

# manually defining the paramer space configuration
par.config = makeParConfig(
  par.set = makeParamSet(
    makeIntegerParam("mtry", lower = 1, upper = 4),
    makeDiscreteParam("ntree", values = c(10, 25, 50))
  ),
  par.vals = list(replace = FALSE),
  learner.name = "randomForest"
)
hyperopt(bh.task, par.config = par.config)
}
